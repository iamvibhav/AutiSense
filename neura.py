# -*- coding: utf-8 -*-
"""neura.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XU0NGnusFCnlfdOtJW02-zUuPWJRB8g4
"""

"""
NEURA: Neurodevelopmental Encryption & Unified Response for Autism

An AI-powered autism detection system with built-in security features, ensuring privacy, encrypted data storage, and role-based access control for doctors, patients, and researchers.
"""


# Install required packages
!pip install pandas numpy scikit-learn matplotlib seaborn gradio cryptography pymongo bcrypt

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
import joblib
import gradio as gr
import os
import json
import bcrypt
import uuid
import time
import datetime
import base64
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC

# Set random seed for reproducibility
np.random.seed(42)

# --------------------------------
# SECURITY AND PRIVACY COMPONENTS
# --------------------------------

class SecurityManager:
    """
    Manages security aspects including authentication, encryption, and access control
    """
    def __init__(self):
        # Generate a key for encryption
        self.generate_key()
        # Initialize user database
        self.users_db = {
            "doctor_1": {
                "password": self.hash_password("doctor123"),
                "role": "doctor",
                "name": "Dr. Smith"
            },
            "patient_1": {
                "password": self.hash_password("patient123"),
                "role": "patient",
                "name": "John Doe",
                "patient_id": "P001"
            },
            "researcher_1": {
                "password": self.hash_password("researcher123"),
                "role": "researcher",
                "name": "Dr. Johnson"
            },
            "admin": {
                "password": self.hash_password("admin123"),
                "role": "admin",
                "name": "Admin User"
            }
        }

        # Define role permissions
        self.permissions = {
            "doctor": ["view_patient_data", "input_data", "run_model", "view_results"],
            "patient": ["view_own_results"],
            "researcher": ["view_anonymized_data", "run_analysis"],
            "admin": ["view_patient_data", "input_data", "run_model", "view_results",
                     "view_anonymized_data", "run_analysis", "manage_users"]
        }

        # Initialize patient records database
        self.patient_records = {}

    def generate_key(self):
        """Generate encryption key based on a password"""
        password = b"autisense_secure_key"
        salt = b"autisense_salt"
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000
        )
        key = base64.urlsafe_b64encode(kdf.derive(password))
        self.cipher_suite = Fernet(key)

    def hash_password(self, password):
        """Hash a password for storing"""
        return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')

    def verify_password(self, stored_hash, provided_password):
        """Verify a stored password against one provided by user"""
        return bcrypt.checkpw(provided_password.encode('utf-8'), stored_hash.encode('utf-8'))

    def authenticate(self, username, password):
        """Authenticate a user"""
        if username in self.users_db:
            if self.verify_password(self.users_db[username]["password"], password):
                return True, self.users_db[username]["role"]
        return False, None

    def has_permission(self, role, permission):
        """Check if a role has a specific permission"""
        if role in self.permissions:
            return permission in self.permissions[role]
        return False

    def encrypt_data(self, data):
        """Encrypt sensitive data"""
        if isinstance(data, str):
            return self.cipher_suite.encrypt(data.encode('utf-8')).decode('utf-8')
        elif isinstance(data, (int, float)):
            return self.cipher_suite.encrypt(str(data).encode('utf-8')).decode('utf-8')
        elif isinstance(data, dict):
            encrypted_data = {}
            for key, value in data.items():
                encrypted_data[key] = self.encrypt_data(value)
            return encrypted_data
        elif isinstance(data, pd.DataFrame):
            df_copy = data.copy()
            sensitive_cols = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10',
                             'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD']
            for col in sensitive_cols:
                if col in df_copy.columns:
                    df_copy[col] = df_copy[col].apply(lambda x: self.encrypt_data(x))
            return df_copy
        return data

    def decrypt_data(self, encrypted_data):
        """Decrypt sensitive data"""
        if isinstance(encrypted_data, str):
            try:
                return self.cipher_suite.decrypt(encrypted_data.encode('utf-8')).decode('utf-8')
            except:
                return encrypted_data
        elif isinstance(encrypted_data, dict):
            decrypted_data = {}
            for key, value in encrypted_data.items():
                decrypted_data[key] = self.decrypt_data(value)
            return decrypted_data
        elif isinstance(encrypted_data, pd.DataFrame):
            df_copy = encrypted_data.copy()
            sensitive_cols = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10',
                             'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD']
            for col in sensitive_cols:
                if col in df_copy.columns:
                    df_copy[col] = df_copy[col].apply(lambda x: self.decrypt_data(x))
            return df_copy
        return encrypted_data

    def add_patient_record(self, patient_id, data, result):
        """Add a patient record to the database"""
        record_id = str(uuid.uuid4())
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # Encrypt sensitive data before storing
        encrypted_data = self.encrypt_data(data)

        self.patient_records[record_id] = {
            "patient_id": patient_id,
            "data": encrypted_data,
            "result": result,
            "timestamp": timestamp
        }
        return record_id

    def get_patient_record(self, record_id):
        """Get a patient record by ID"""
        if record_id in self.patient_records:
            record = self.patient_records[record_id]
            # Decrypt data before returning
            decrypted_record = record.copy()
            decrypted_record["data"] = self.decrypt_data(record["data"])
            return decrypted_record
        return None

    def get_patient_records_by_patient_id(self, patient_id):
        """Get all records for a specific patient"""
        patient_records = []
        for record_id, record in self.patient_records.items():
            if record["patient_id"] == patient_id:
                decrypted_record = record.copy()
                decrypted_record["data"] = self.decrypt_data(record["data"])
                decrypted_record["record_id"] = record_id
                patient_records.append(decrypted_record)
        return patient_records

    def save_patient_records(self, filename="patient_records.json"):
        """Save patient records to a file"""
        with open(filename, 'w') as f:
            json.dump(self.patient_records, f)

    def load_patient_records(self, filename="patient_records.json"):
        """Load patient records from a file"""
        if os.path.exists(filename):
            with open(filename, 'r') as f:
                self.patient_records = json.load(f)


class PrivacyManager:
    """
    Manages data privacy features including anonymization and perturbation
    """
    def __init__(self):
        self.epsilon = 0.5  # Privacy budget for differential privacy

    def anonymize_data(self, data):
        """Anonymize data by removing direct identifiers"""
        if isinstance(data, pd.DataFrame):
            df_copy = data.copy()

            # Remove direct identifiers
            identifiers = ['patient_id', 'name', 'address', 'phone', 'email']
            for col in identifiers:
                if col in df_copy.columns:
                    df_copy = df_copy.drop(columns=[col])

            return df_copy
        return data

    def perturb_data(self, data):
        """
        Apply differential privacy by adding noise to sensitive numerical data
        This implements the Laplace mechanism for differential privacy
        """
        if isinstance(data, pd.DataFrame):
            df_copy = data.copy()

            # Apply perturbation to numerical columns
            numerical_cols = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']

            for col in numerical_cols:
                if col in df_copy.columns and pd.api.types.is_numeric_dtype(df_copy[col]):
                    # Add Laplace noise with scale=sensitivity/epsilon
                    sensitivity = 1.0  # Assuming sensitivity of 1 for binary features
                    scale = sensitivity / self.epsilon
                    noise = np.random.laplace(0, scale, size=len(df_copy))
                    df_copy[col] = df_copy[col] + noise

                    # Ensure values stay in valid range (0-1 for A1-A10, positive for Age_Mons)
                    if col.startswith('A'):
                        df_copy[col] = df_copy[col].clip(0, 1)
                    elif col == 'Age_Mons':
                        df_copy[col] = df_copy[col].clip(0)

            return df_copy
        return data

    def generate_research_dataset(self, original_data, num_samples=None):
        """
        Generate a research-friendly dataset with privacy protections
        This applies both anonymization and perturbation
        """
        # First anonymize the data
        anonymized_data = self.anonymize_data(original_data)

        # Then apply perturbation for differential privacy
        perturbed_data = self.perturb_data(anonymized_data)

        # Optionally sample a subset of records
        if num_samples and num_samples < len(perturbed_data):
            sampled_data = perturbed_data.sample(n=num_samples, random_state=42)
            return sampled_data

        return perturbed_data


# --------------------------------
# DATA LOADING AND PREPROCESSING
# --------------------------------

def load_and_preprocess_data():
    """
    Load and preprocess the dataset correctly.
    """
    print("Please upload your dataset file:")
    uploaded = files.upload()

    # Get the uploaded file name
    file_name = list(uploaded.keys())[0]

    # Load the dataset
    df = pd.read_csv(file_name)
    print("Dataset loaded successfully!")

    # Fix column names (strip spaces)
    df.columns = df.columns.str.strip()

    # Define column types
    numeric_cols = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']
    categorical_cols = ['Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who completed the test']

    # Fill missing values
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())  # Fill numeric NaNs with mean
    df[categorical_cols] = df[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))  # Fill categorical NaNs with mode

    # Fix inconsistencies in categorical values
    df['Who completed the test'] = df['Who completed the test'].str.strip().str.lower()  # Convert to lowercase & remove spaces

    # Encode categorical features
    label_encoders = {}
    for col in categorical_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))  # Ensure consistent formatting
        label_encoders[col] = le

    # Prepare features and target
    features_to_drop = ['Case_No', 'Qchat-10-Score']  # Drop unnecessary columns
    if all(col in df.columns for col in features_to_drop + ['Class/ASD Traits']):
        X = df.drop(columns=features_to_drop + ['Class/ASD Traits'])
        y = df['Class/ASD Traits'].map({'Yes': 1, 'No': 0})  # Convert target to binary
    else:
        # If some columns don't exist, adapt accordingly
        cols_to_drop = [col for col in features_to_drop if col in df.columns]
        if 'Class/ASD Traits' in df.columns:
            cols_to_drop.append('Class/ASD Traits')
            X = df.drop(columns=cols_to_drop)
            y = df['Class/ASD Traits'].map({'Yes': 1, 'No': 0})
        else:
            X = df.drop(columns=cols_to_drop)
            y = None
            print("Warning: Target column 'Class/ASD Traits' not found. Model training will be skipped.")

    # Scale numeric features
    scaler = StandardScaler()
    X[numeric_cols] = scaler.fit_transform(X[numeric_cols])

    return X, y, label_encoders, scaler, numeric_cols, categorical_cols, df


# --------------------------------
# MODEL TRAINING AND EVALUATION
# --------------------------------

def train_adaboost_model(X_train, y_train, X_test, y_test):
    """
    Train an AdaBoost model with optimized hyperparameters
    """
    # Define the model with default parameters
    adaboost = AdaBoostClassifier(
        estimator=DecisionTreeClassifier(max_depth=2),
        n_estimators=100,
        learning_rate=0.1,
        random_state=42
    )

    # Train the model
    adaboost.fit(X_train, y_train)

    # Evaluate on test set
    y_pred = adaboost.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"AdaBoost Model Accuracy: {accuracy:.4f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap="Blues")
    plt.title("AdaBoost Model Confusion Matrix")
    plt.show()

    return adaboost


def plot_feature_importance(model, feature_names):
    """
    Plot feature importance for tree-based models
    """
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        sorted_idx = np.argsort(importances)
        plt.figure(figsize=(10, 6))
        plt.barh(range(len(sorted_idx)), importances[sorted_idx])
        plt.yticks(range(len(sorted_idx)), np.array(feature_names)[sorted_idx])
        plt.xlabel('Feature Importance')
        plt.title('Feature Importance in Model')
        plt.tight_layout()
        plt.show()


# --------------------------------
# GRADIO UI COMPONENTS
# --------------------------------

class AutiSenseUI:
    """
    Manages the Gradio user interface for AutiSense
    """
    def __init__(self, model, scaler, label_encoders, security_manager, privacy_manager,
                numeric_cols, categorical_cols):
        self.model = model
        self.scaler = scaler
        self.label_encoders = label_encoders
        self.security_manager = security_manager
        self.privacy_manager = privacy_manager
        self.numeric_cols = numeric_cols
        self.categorical_cols = categorical_cols
        self.current_user = None
        self.current_role = None

    def login(self, username, password):
        """Handle user login"""
        success, role = self.security_manager.authenticate(username, password)
        if success:
            self.current_user = username
            self.current_role = role
            user_info = self.security_manager.users_db[username]
            return f"Login successful! Welcome, {user_info['name']} (Role: {role.capitalize()})"
        else:
            return "Login failed. Invalid username or password."

    def predict_autism(self, A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, Age_Mons,
                      Sex, Ethnicity, Jaundice, Family_mem_with_ASD, Who_completed_test, patient_id):
        """Process inputs and make prediction"""
        # Check permissions
        if not self.current_role or not self.security_manager.has_permission(self.current_role, "run_model"):
            return "Error: You do not have permission to run the model."

        # Create a DataFrame from user input
        input_data = {
            "A1": A1, "A2": A2, "A3": A3, "A4": A4, "A5": A5,
            "A6": A6, "A7": A7, "A8": A8, "A9": A9, "A10": A10,
            "Age_Mons": Age_Mons, "Sex": Sex, "Ethnicity": Ethnicity,
            "Jaundice": Jaundice, "Family_mem_with_ASD": Family_mem_with_ASD,
            "Who completed the test": Who_completed_test
        }

        df_input = pd.DataFrame([input_data])

        # Mapping categorical inputs to match trained model
        category_mappings = {
            "Sex": {"Male": "m", "Female": "f"},
            "Jaundice": {"Yes": "yes", "No": "no"},
            "Family_mem_with_ASD": {"Yes": "yes", "No": "no"},
            "Who completed the test": {
                "Family Member": "family member",
                "Health Care Professional": "health care professional",
                "Others": "others",
                "Self": "self"
            }
        }

        # Apply mappings safely
        for col, mapping in category_mappings.items():
            df_input[col] = df_input[col].apply(lambda x: mapping.get(x, x))

        # Process categorical features
        for col in self.categorical_cols:
            if col in self.label_encoders:
                df_input[col] = self.label_encoders[col].transform(df_input[col])

        # Scale numeric features
        df_input[self.numeric_cols] = self.scaler.transform(df_input[self.numeric_cols])

        # Predict autism traits
        prediction = self.model.predict(df_input)[0]
        probabilities = self.model.predict_proba(df_input)[0]

        # Store the result in the database
        result = {
            "prediction": int(prediction),
            "probability_no_traits": float(probabilities[0]),
            "probability_traits": float(probabilities[1])
        }

        record_id = self.security_manager.add_patient_record(patient_id, input_data, result)

        # Format the output text
        output = f"ðŸ“‹ Assessment Results for Patient ID: {patient_id}\n\n"
        output += f"ðŸ”¹ Prediction: {'Autistic Traits Detected' if prediction == 1 else 'No Autistic Traits Detected'}\n\n"
        output += f"ðŸ”¹ Confidence Scores:\n"
        output += f"   â€¢ No Autistic Traits: {probabilities[0]:.2%}\n"
        output += f"   â€¢ Autistic Traits: {probabilities[1]:.2%}\n\n"
        output += f"ðŸ”¹ Record ID: {record_id}\n"
        output += f"ðŸ”¹ Assessment Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"

        # Save records to file for persistence
        self.security_manager.save_patient_records()

        return output

    def get_patient_results(self, patient_id):
        """Retrieve results for a specific patient"""
        # Check permissions and ownership
        if not self.current_role:
            return "Error: You must be logged in to view results."

        # Patients can only see their own results
        if self.current_role == "patient":
            user_info = self.security_manager.users_db[self.current_user]
            if user_info.get("patient_id") != patient_id:
                return "Error: You can only view your own results."

        # Check if doctor or admin has permission
        if self.current_role in ["doctor", "admin"]:
            if not self.security_manager.has_permission(self.current_role, "view_results"):
                return "Error: You do not have permission to view patient results."

        # Retrieve patient records
        records = self.security_manager.get_patient_records_by_patient_id(patient_id)

        if not records:
            return f"No records found for Patient ID: {patient_id}"

        # Format the results
        output = f"ðŸ“‹ Patient Records for ID: {patient_id}\n\n"

        for i, record in enumerate(records):
            output += f"Record #{i+1} (ID: {record['record_id']})\n"
            output += f"Date: {record['timestamp']}\n"
            output += f"Prediction: {'Autistic Traits Detected' if record['result']['prediction'] == 1 else 'No Autistic Traits Detected'}\n"
            output += f"Confidence: {record['result']['probability_traits']:.2%}\n\n"

        return output

    def get_research_data(self, num_samples=50):
        """Generate anonymized research data"""
        # Check permissions
        if not self.current_role or not self.security_manager.has_permission(self.current_role, "view_anonymized_data"):
            return "Error: You do not have permission to access research data."

        # Extract all patient data
        records_data = []
        for record_id, record in self.security_manager.patient_records.items():
            # Decrypt the data
            decrypted_data = self.security_manager.decrypt_data(record["data"])
            # Add the result
            data_with_result = decrypted_data.copy()
            data_with_result["prediction"] = record["result"]["prediction"]
            records_data.append(data_with_result)

        # Convert to DataFrame
        if not records_data:
            return "No data available for research."

        df_records = pd.DataFrame(records_data)

        # Apply privacy mechanisms
        anonymized_data = self.privacy_manager.generate_research_dataset(df_records, num_samples)

        # Calculate statistics for research
        stats = {
            "total_records": len(anonymized_data),
            "positive_cases": anonymized_data["prediction"].sum(),
            "negative_cases": len(anonymized_data) - anonymized_data["prediction"].sum(),
            "positive_rate": anonymized_data["prediction"].mean(),
            "average_age_months": anonymized_data["Age_Mons"].mean() if "Age_Mons" in anonymized_data else "N/A"
        }

        # Format the output
        output = "ðŸ“Š Anonymized Research Data Summary\n\n"
        output += f"Total Records: {stats['total_records']}\n"
        output += f"Positive Cases: {stats['positive_cases']} ({stats['positive_rate']:.2%})\n"
        output += f"Negative Cases: {stats['negative_cases']} ({1-stats['positive_rate']:.2%})\n"
        output += f"Average Age (months): {stats['average_age_months']:.1f}\n\n"

        # Feature correlations with prediction
        if len(anonymized_data) > 5:  # Only calculate correlations if enough data
            corr_data = anonymized_data.copy()
            for col in self.numeric_cols:
                if col in corr_data.columns:
                    correlation = corr_data[col].corr(corr_data["prediction"])
                    output += f"Correlation of {col} with prediction: {correlation:.3f}\n"

        return output

    def create_interface(self):
        """Create the Gradio interface with multiple tabs for different roles"""
        with gr.Blocks(title="ðŸ§  AutiSense: Secure Autism Traits Detection") as interface:
            gr.Markdown("# ðŸ§  AutiSense: Secure Autism Traits Detection")
            gr.Markdown("### Login to access the system")

            # Login section
            with gr.Row():
                with gr.Column(scale=1):
                    username_input = gr.Textbox(label="Username")
                    password_input = gr.Textbox(label="Password", type="password")
                    login_button = gr.Button("Login")
                    login_output = gr.Textbox(label="Login Status", interactive=False)

            # Connect login button
            login_button.click(
                fn=self.login,
                inputs=[username_input, password_input],
                outputs=login_output
            )

            gr.Markdown("### System Features")

            # Tabs for different functionalities
            with gr.Tabs() as tabs:
                # Assessment Tab (for doctors)
                with gr.TabItem("Patient Assessment"):
                    gr.Markdown("#### Enter Patient Information for Assessment")
                    with gr.Row():
                        with gr.Column(scale=1):
                            patient_id_input = gr.Textbox(label="Patient ID")
                            a1 = gr.Radio([0, 1], label="A1: Does your child look at you when you call his/her name?", value=0)
                            a2 = gr.Radio([0, 1], label="A2: How easy is it for you to get eye contact with your child?", value=0)
                            a3 = gr.Radio([0, 1], label="A3: Does your child point to indicate that s/he wants something?", value=0)
                            a4 = gr.Radio([0, 1], label="A4: Does your child point to share interest with you?", value=0)
                            a5 = gr.Radio([0, 1], label="A5: Does your child pretend?", value=0)
                        with gr.Column(scale=1):
                            a6 = gr.Radio([0, 1], label="A6: Does your child follow where you're looking?", value=0)
                            a7 = gr.Radio([0, 1], label="A7: If you or someone else in the family is visibly upset, does your child show signs of wanting to comfort them?", value=0)
                            a8 = gr.Radio([0, 1], label="A8: Would you describe your child's first words as:", value=0)
                            a9 = gr.Radio([0, 1], label="A9: Does your child use simple gestures?", value=0)
                            a10 = gr.Radio([0, 1], label="A10: Does your child stare at nothing with no apparent purpose?", value=0)

                    with gr.Row():
                        with gr.Column(scale=1):
                            age_mons = gr.Number(label="Age (Months)", value=36, minimum=0, maximum=240)
                            sex = gr.Dropdown(["Male", "Female"], label="Sex", value="Male")
                            ethnicity = gr.Dropdown(["White European", "Middle Eastern", "Asian", "Black", "Hispanic", "Latino", "Other"], label="Ethnicity", value="White European")

                        with gr.Column(scale=1):
                            jaundice = gr.Dropdown(["Yes", "No"], label="Jaundice", value="No")
                            family_asd = gr.Dropdown(["Yes", "No"], label="Family History of ASD", value="No")
                            completed_by = gr.Dropdown(["Family Member", "Health Care Professional", "Self", "Others"], label="Who Completed the Test", value="Family Member")

                    predict_button = gr.Button("Run Assessment")
                    prediction_output = gr.Textbox(label="Assessment Results", interactive=False)

                # Patient Results Tab (for patients)
                with gr.TabItem("Patient Results"):
                    gr.Markdown("#### View Patient Results")
                    patient_id_lookup = gr.Textbox(label="Enter Patient ID")
                    lookup_button = gr.Button("View Results")
                    results_output = gr.Textbox(label="Patient Results", interactive=False)

                # Research Tab (for researchers)
                with gr.TabItem("Research Data"):
                    gr.Markdown("#### Access Anonymized Research Data")
                    num_samples = gr.Slider(minimum=10, maximum=100, value=50, step=10, label="Number of Samples")
                    research_button = gr.Button("Generate Research Dataset")
                    research_output = gr.Textbox(label="Research Data Summary", interactive=False)

            # Connect buttons to functions
            predict_button.click(
                fn=self.predict_autism,
                inputs=[a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, age_mons,
                       sex, ethnicity, jaundice, family_asd, completed_by, patient_id_input],
                               outputs=prediction_output
            )

            lookup_button.click(
                fn=self.get_patient_results,
                inputs=[patient_id_lookup],
                outputs=results_output
            )

            research_button.click(
                fn=self.get_research_data,
                inputs=[num_samples],
                outputs=research_output
            )

        return interface


# --------------------------------
# MAIN EXECUTION
# --------------------------------

if __name__ == "__main__":
    # Load and preprocess data
    X, y, label_encoders, scaler, numeric_cols, categorical_cols, df = load_and_preprocess_data()

    # Split the dataset (if y is available)
    if y is not None:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
        model = train_adaboost_model(X_train, y_train, X_test, y_test)
    else:
        model = None

    # Initialize security and privacy managers
    security_manager = SecurityManager()
    privacy_manager = PrivacyManager()

    # Initialize the UI
    if model:
        ui = AutiSenseUI(model, scaler, label_encoders, security_manager, privacy_manager, numeric_cols, categorical_cols)
        gradio_interface = ui.create_interface()
        gradio_interface.launch(share=True)
    else:
        print("Error: Model could not be trained. Check dataset format.")